{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ce8079-c3b4-4537-844e-7e6d6706e923",
   "metadata": {},
   "source": [
    "# Lab 1: Building your Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c9a24-4d77-43ca-84fd-5155b4e4c777",
   "metadata": {},
   "source": [
    "The agent is comprised of a router using OpenAI function calling, and a set of three tools: a database lookup tool, a data analysis tool, and a code generator to create graphs.\n",
    "\n",
    "<img src=\"images/agent.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "The agent can lookup information from a local file, perform analysis on that information, and graph results. The example local file is a log of transactions at a local store. The agent can help the store owners understand trends and anomalies in their sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a4f62-de25-4a66-8cdb-f33d1e92ad92",
   "metadata": {},
   "source": [
    "## Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db840f4-4b3a-4bd0-91fd-7b94d895c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib64/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~riton (/opt/app-root/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install tavily-python \n",
    "!pip install pymilvus==2.3.6 duckdb --quiet\n",
    "!pip install -U tavily-python langchain_community sentence-transformers --quiet\n",
    "!pip install autogen-agentchat~=0.2 autogen psutil --quiet\n",
    "# !pip install -q langchain-openai termcolor langchain_community duckduckgo_search wikipedia openapi-python-client==0.12.3 langgraph langchain_experimental yfinance\n",
    "!pip install -q langchain-openai langchain-anthropic termcolor langchain_community duckduckgo_search wikipedia openapi-python-client langgraph langchain_experimental openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d6c602-28a5-42f2-9e53-33dac5846cba",
   "metadata": {
    "height": 148
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# from helper import get_openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd227e-0d4f-4f64-922c-cc4606a10090",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> 💻 &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix – Tips, Help, and Download\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf15696-0cfa-464a-b698-b5877cbbd6b3",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> 🚨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7f1fb-fea2-475b-9a90-a70eea108153",
   "metadata": {},
   "source": [
    "## Initializing the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bbb872-2328-4283-b544-9a4c6ba960d3",
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": [
    "# initialize the OpenAI client\n",
    "# openai_api_key = get_openai_api_key()\n",
    "# client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46252045-26a2-4b9b-9124-660c5fd84b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ['ATHINA_API_KEY'] = \"IhrJrr0krTMRA9ogqi5aaD4ZuYuvMcdG\"\n",
    "\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL = \"Qwen/Qwen3-14B\"\n",
    "# MODEL =\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# MODEL_NAME = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "MODEL=\"ibm-granite/granite-3.3-2b-instruct\"\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    api_key=API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503d9fe-e023-4446-b1b2-4633ab0efd8e",
   "metadata": {},
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f909b1-689e-4d61-8f8d-c6f35520ad66",
   "metadata": {},
   "source": [
    "Let's start by creating the three tools the agent will be able to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded04f0-ea0d-48b1-83d0-1bfc84ea170e",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761c2e1-b100-4d3c-b4d7-8c3b4b709c54",
   "metadata": {},
   "source": [
    "This first tool reads from a local parquet file that contains the transaction data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78dbdaf9-d5e0-4f0d-aa41-318020ab7b1e",
   "metadata": {
    "height": 63
   },
   "outputs": [],
   "source": [
    "# define the path to the transactional data\n",
    "TRANSACTION_DATA_FILE_PATH = 'data/Store_Sales_Price_Elasticity_Promotions_Data.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a0d24-185a-47a4-a27b-3959cb1e0ba1",
   "metadata": {},
   "source": [
    "This database lookup tool works using three steps. \n",
    "\n",
    "<img src=\"images/tool1.png\" width=\"500\"/>\n",
    "\n",
    "1. First, it creates the SQL table from a local file, if not already done.\n",
    "2. Second, it translates the original prompt into an sql query (using an LLM call).\n",
    "3. Finally, it runs that query against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd37619-7785-41de-9986-6260d6e17221",
   "metadata": {
    "height": 165
   },
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 1\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b7c2f28-2ec1-43de-b555-d300d916c47d",
   "metadata": {
    "height": 250
   },
   "outputs": [],
   "source": [
    "# code for step 2 of tool 1\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    columns=columns, \n",
    "                                                    table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb59fa5-f096-4ba6-9967-4dffea8aa5cb",
   "metadata": {
    "height": 437
   },
   "outputs": [],
   "source": [
    "# code for tool 1\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "\n",
    "        # define the table name\n",
    "        table_name = \"sales\"\n",
    "        \n",
    "        # step 1: read the parquet file into a DuckDB table\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # step 2: generate the SQL code\n",
    "        sql_query = generate_sql_query(prompt, df.columns, table_name)\n",
    "        # clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "        # step 3: execute the SQL query\n",
    "        result = duckdb.sql(sql_query).df()\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044f10e-6fd1-4514-94b5-3d62fe2b23d1",
   "metadata": {},
   "source": [
    "Great! Now let's test the first tool and make sure it worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7391d9ff-55f1-4b1d-bfe5-a4df403bf4b9",
   "metadata": {
    "height": 63
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Store_Number  SKU_Coded  Product_Class_Code  Sold_Date  Qty_Sold  Total_Sale_Value  On_Promo\n",
      "0           1320    6173050               22875 2021-11-01         1          4.990000         0\n",
      "1           1320    6174250               22875 2021-11-01         1          0.890000         0\n",
      "2           1320    6176200               22975 2021-11-01         2         99.980003         0\n",
      "3           1320    6176800               22800 2021-11-01         1         14.970000         0\n",
      "4           1320    6177250               22975 2021-11-01         1          6.890000         0\n",
      "5           1320    6177300               22800 2021-11-01         1          9.990000         0\n",
      "6           1320    6177350               22800 2021-11-01         2         16.980000         0\n",
      "7           1320    6177700               22875 2021-11-01         1          3.190000         0\n",
      "8           1320    6178000               22875 2021-11-01         2          6.380000         0\n",
      "9           1320    6178250               22800 2021-11-01         1         16.590000         0\n",
      "10          1320    6179250               24400 2021-11-01         1         14.990000         0\n",
      "11          1320    6179300               22800 2021-11-01         2          9.980000         0\n",
      "12          1320    6179400               24400 2021-11-01         2         29.980000         0\n",
      "13          1320    6179450               24400 2021-11-01         1         14.990000         0\n",
      "14          1320    6179500               24400 2021-11-01         1         14.990000         0\n",
      "15          1320    6179750               22800 2021-11-01         2         39.980000         0\n",
      "16          1320    6180550               22975 2021-11-01         1         15.990000         0\n",
      "17          1320    6182050               22975 2021-11-01         1          7.990000         0\n",
      "18          1320    6183750               22850 2021-11-01         3         38.970001         0\n",
      "19          1320    6184100               22975 2021-11-01         3         59.970001         0\n",
      "20          1320    6188550               22950 2021-11-01         2         15.980000         0\n",
      "21          1320    6190050               24425 2021-11-01         5         19.950001         0\n",
      "22          1320    6190150               24425 2021-11-01         1          8.990000         0\n",
      "23          1320    6190200               24425 2021-11-01         1          8.990000         0\n",
      "24          1320    6190250               24425 2021-11-01         1          7.990000         0\n",
      "25          1320    6190350               22950 2021-11-01         1          6.990000         0\n",
      "26          1320    6190400               22950 2021-11-01         1          6.990000         0\n",
      "27          1320    6193750               22875 2021-11-01         1          6.990000         0\n",
      "28          1320    6195350               24375 2021-11-01         1         16.990000         0\n",
      "29          1320    6195800               22850 2021-11-01         3         25.719999         1\n"
     ]
    }
   ],
   "source": [
    "example_data = lookup_sales_data(\"Show me all the sales for store 1320 on November 1st, 2021\")\n",
    "print(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481388d3-578d-492b-a53c-46811ac573d7",
   "metadata": {},
   "source": [
    "### Tool 2: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a6d53-fcae-41bd-9d3c-e90960874737",
   "metadata": {},
   "source": [
    "The second tool can analyze the returned data and display conclusions to users.\n",
    "\n",
    "<img src=\"images/tool2.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3510f56-30c5-446d-a41f-bec5e4a1de36",
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "# Construct prompt based on analysis type and data subset\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23cb7932-79be-455f-b4fb-83db752d5e43",
   "metadata": {
    "height": 233
   },
   "outputs": [],
   "source": [
    "# code for tool 2\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97ea8e-c101-4e1b-88d0-8ce088590373",
   "metadata": {},
   "source": [
    "This tool is relatively simple, but let's still test it out to be sure things are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18042c0f-ba38-4ebd-925c-9bc7ae0f0b21",
   "metadata": {
    "height": 63
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To analyze the given data, we will examine trends in terms of Total_Sale_Value, considering the relationship between SKU_Coded, Product_Class_Code, On_Promo, and Qty_Sold.\n",
      "\n",
      "### Trends Observations:\n",
      "\n",
      "1. **SKU_Coded Distribution**:\n",
      "   - There are 29 rows, each representing a distinct SKU. There is no clear pattern or sequence in the SKU_Coded values; they appear to be randomly distributed. \n",
      "\n",
      "2. **Product_Class_Code Distribution**:\n",
      "   - As there are 29 rows and different Product_Class_Code codes for each SKU, it appears that these codes are also distributed randomly across the dataset.\n",
      "\n",
      "3. **Sales Value Pattern**:\n",
      "\n",
      "   - **Total_Sale_Value**: Since we have a clear numerical distribution of Total_Sale_Value, let's analyze the trends within this metric:\n",
      "\n",
      "     - **Minimum and Maximum Values**:\n",
      "       - The minimum sale value is $3.19 (Record 7), while the maximum is $38.97 (Record 18).\n",
      "\n",
      "     - **Median Value**:\n",
      "       - With 29 data points, the median sale value falls at the 15th value (i.e., Record 15), which is $39.98.\n",
      "\n",
      "     - **Distribution**:\n",
      "       - The data suggests a positive relationship between Total_Sale_Value and Qty_Sold in the majority of cases. Higher quantities sold typically result in higher total sale values with a few exceptions (Records 7, 17, and 29, where lower Qty_Sold lead to higher sales values), likely due to higher individual unit prices.\n",
      "    \n",
      "4. **On_Promo Boundary**:\n",
      "   - **Promotion Status**:\n",
      "     - Records 1, 2, 4, 5, 13, 14, and the exceptions (Records 7, 17, 27, 29) carry a “On_Promo” value of 0, while Records 2, 3, 6, 9, 11, 12, 16, 19, 20, 22, and 23 carry a “On_Promo” value of either 0 or 1.\n",
      "     - There is a trend where most records not marked with \"On_Promo\" (Records 1, 2, 4, 5, 13, 14, 17, 22, 23, 27) have lower sale values relative to those on promotion (Records 2, 3, 6, 9, 11, 12, 16, 19, 20, 22, 25, 26).\n",
      "\n",
      "5. **Extension by SKU Quantity Sold**:\n",
      "   - A clear positive trend exists where the amount (Quantity Sold) is somewhat linearly related to Total_Sale_Value, considering the exceptions noted. With increasing Qty_Sold, Total_Sale_Value generally increases, except for outliers.\n",
      "\n",
      "### Conclusion:\n",
      "\n",
      "- Generally, there is a strong correlation between increasing Qty_Sold and higher Total_Sale_Value, suggesting effective inventory management during higher sales volumes.\n",
      "- Promotional activities (On_Promo value of 1) seem to have a notable impact on Total_Sale_Value, often leading to higher revenues, although some records indicate promotions could be more effective under specific conditions (like Records 7, 17, and 29, which have higher unit prices but non-zero \"On_Promo\" status).\n",
      "- SKU_Coded and Product_Class_Code items broadly do not show a distinct pattern here; their influence appears minimal in comparison to the influence of Qty_Sold and promotional status on Total_Sale_Value.\n",
      "\n",
      "Overall, the data suggests that for SKUs with no promotional markups (On_Promo=0), higher unit sales typically accompany increased sales revenue. Conversely, promotional timing seems crucial for specific items to boost revenue across varying quantities sold.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_sales_data(prompt=\"what trends do you see in this data\", \n",
    "                         data=example_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b071118-7538-4e21-a709-f50dcc606260",
   "metadata": {},
   "source": [
    "### Tool 3: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b694537-bafd-4df3-8354-0b6083d3d7ea",
   "metadata": {},
   "source": [
    "The third tool generates python code to create the requested graphs from the returned data of the first tool. It consists of two steps:\n",
    "<img src=\"images/tool3.png\" width=\"500\"/>\n",
    "1. First, it creates the chart configuration: chart type, title, data, lables for x-axis and y-axis (using an LLM call).\n",
    "2. Second, it generates the python code based on the chart configuration of the first step (using an LLM call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5faad9a1-4452-4b89-98e6-c6a8a09f98cf",
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "# prompt template for step 1 of tool 3\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd462935-d2c5-4de1-a094-b7bdf951cd66",
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "# class defining the response format of step 1 of tool 3\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3396ccea-1e06-42fa-a667-2d8fc8332df7",
   "metadata": {
    "height": 709
   },
   "outputs": [],
   "source": [
    "# code for step 1 of tool 3\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data,\n",
    "                                                         visualization_goal=visualization_goal)\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0473365-8fb6-4e30-962d-9599cf514323",
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 3\n",
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0832853e-e7dd-44eb-8fec-8f4524b9baa4",
   "metadata": {
    "height": 284
   },
   "outputs": [],
   "source": [
    "# code for step 2 of tool 3\n",
    "def create_chart(config: dict) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e4e96e8-0ec3-4580-be1e-d239d26c609b",
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "# code for tool 3\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675259b-2978-4f08-bffa-804f0a65395c",
   "metadata": {},
   "source": [
    "Great, now let's try the third tool out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001d0743-5b02-4cfc-a6a4-5b0bba80ea30",
   "metadata": {
    "height": 80
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "data = [{'Store_Number': 1320,\n",
      "         'SKU_Coded': 6173050,\n",
      "         'Product_Class_Code': '6173050',\n",
      "         'Sold_Date': '2021-11-01',\n",
      "         'Qty_Sold': 22875,\n",
      "         'Total_Sale_Value': 4.990000,\n",
      "         'On_Promo': 0\n",
      "        },\n",
      "        {'Store_Number': 1320,\n",
      "         'SKU_Coded': 6174250,\n",
      "         'Product_Class_Code': '6174250',\n",
      "         'Sold_Date': '2021-11-01',\n",
      "         'Qty_Sold': 22875,\n",
      "         'Total_Sale_Value': 0.890000,\n",
      "         'On_Promo': 0\n",
      "        },\n",
      "        # ... rest of the data ...\n",
      "    ]\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "df['Sold_Date'] = pd.to_datetime(df['Sold_Date'])\n",
      "df.set_index('Sold_Date', inplace=True)\n",
      "\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.plot(df['Total_Sale_Value'], marker='o')\n",
      "plt.title('A line chart of sales by product SKU.')\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel('Total Sale Value')\n",
      "plt.xticks(rotation=45)\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "\n",
      "Since creating a bar chart as per the configuration is unexpected (the given data is in a list of dicts and not a structured format for a bar chart), I've created a line chart based on the 'Total_Sale_Value'. The chart will display sales data over time.\n"
     ]
    }
   ],
   "source": [
    "code = generate_visualization(example_data, \n",
    "                              \"A bar chart of sales by product SKU. Put the product SKU on the x-axis and the sales on the y-axis.\")\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a56266f-790d-4208-9788-02cab6cabfe9",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "# exec(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7653b-a90d-4447-9b6b-646b00e5164b",
   "metadata": {},
   "source": [
    "## Defining the Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b823b2a6-1567-4a03-b829-22f6a3e167ea",
   "metadata": {},
   "source": [
    "Now that all of the tools are defined, you can create the router. The router will take the original user input, and is responsible for calling any tools. After each tool call is completed, the agent will return to router to determine whether another tool should be called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658c1a5-6328-4ca1-bdcf-7c03328aa0c8",
   "metadata": {},
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf85e6a-c708-4ed5-8f43-e996c5f38c7f",
   "metadata": {},
   "source": [
    "Let's define the tools in a way that can be understood by our OpenAI model. OpenAI understands a specific JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35f5886-32d7-4bc3-968b-4485ce20d7a3",
   "metadata": {
    "height": 947
   },
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\", \n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data, \n",
    "    \"generate_visualization\": generate_visualization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291cea7-d45f-429c-845a-53ba8cfc7485",
   "metadata": {},
   "source": [
    "### Router Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7edb47-99cc-45d0-8d13-5d6238aee2a2",
   "metadata": {},
   "source": [
    "The router is composed of a main loop method, and a method to handle the tool calls that you get back from the model.\n",
    "\n",
    "<img src=\"images/router.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f87aa9",
   "metadata": {},
   "source": [
    "The following two cells define the function `handle_tool_calls` and the variable `SYSTEM_PROMPT`, which will be used by the function `run_agent` defining the router logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce938658-35c9-4cda-b0d8-0b89494830c4",
   "metadata": {
    "height": 199
   },
   "outputs": [],
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b24bce5-477f-4e21-af18-4b784282aaa1",
   "metadata": {
    "height": 80
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0eacdb0-d8c4-4686-9fda-7b7c12ae2c35",
   "metadata": {
    "height": 556
   },
   "outputs": [],
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "        \n",
    "    # Check and add system prompt if needed\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        print(\"Making router call to OpenAI\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        messages.append(response.choices[0].message)\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "\n",
    "        # if the model decides to call function(s), call handle_tool_calls\n",
    "        if tool_calls:\n",
    "            print(\"Processing tool calls\")\n",
    "            messages = handle_tool_calls(tool_calls, messages)\n",
    "        else:\n",
    "            print(\"No tool calls, returning final response\")\n",
    "            return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5bb8861-7304-4d4a-ac8b-6ca1d7193e59",
   "metadata": {
    "height": 46
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent with messages: Show me the code for graph of sales by store in Nov 2021, and tell me what trends you see.\n",
      "Making router call to OpenAI\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n"
     ]
    }
   ],
   "source": [
    "result = run_agent('Show me the code for graph of sales by store in Nov 2021, and tell me what trends you see.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1a59674-5bb3-4983-95ca-809e26743e87",
   "metadata": {
    "height": 63
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To analyze and visualize the sales data by store for November 2021, I'll first look up the relevant data and then generate a visualization code. Here's our approach:\n",
      "\n",
      "1. The `lookup_sales_data` function will provide the actual sales data for the November 2021 period across different stores.\n",
      "2. After retrieving the data, the `analyze_sales_data` function will assist in extracting trends and insights from the dataset.\n",
      "3. Finally, the `generate_visualization` function will create a Python code snippet based on the analyzed data to produce a visualization (like a bar chart or line graph).\n",
      "\n",
      "Let's proceed with these steps:\n",
      "\n",
      "- I will use the `lookup_sales_data` function to fetch the required data.\n",
      "- Once I have that, `analyze_sales_data` will help in identifying patterns in sales by store.\n",
      "- Finally, `generate_visualization` will create Python code for a visualization of this sales data.\n",
      "\n",
      "Please, provide access to execute these functions, so we can generate the visualization code and identify trends. Because I am a text-based AI, I can't directly execute Python code or access external databases to get the data in real-time. However, I can lead you on the correct path to achieve this from within our simulation environment.\n",
      "\n",
      "Suppose, after fetching and analyzing data, insights are as follows:\n",
      "\n",
      "- Trends in sales vary widely across different stores.\n",
      "- Some stores exhibit a significant uplift in sales, possibly due to specific promotions.\n",
      "- Others show a slight increase, possibly depending on seasonality or customer base size.\n",
      "- In some regional segments, there is a consistent increase in sales compared to the previous month and the same period last year.\n",
      "\n",
      "With this analytical foundation, we could then develop a Python code snippet for visualization such as:\n",
      "\n",
      "```python\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "\n",
      "# Suppose df_sales is the DataFrame containing the sales data\n",
      "# from the latest lookup_sales_data call, including 'Store', 'Sale_Date', and 'Sales'\n",
      "\n",
      "# Filtering for November 2021\n",
      "nov_ Sales_data = df_sales[(pd.to_datetime(df_sales['Sale_Date']).dt.month == 11)]\n",
      "\n",
      "# Create a bar chart\n",
      "nov_Sales_data.groupby('Store')['Sales'].sum().plot(kind='bar')\n",
      "plt.title('Sales by Store in November 2021')\n",
      "plt.xlabel('Store')\n",
      "plt.ylabel('Total Sales')\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "Please allow me to fetch the real data and run this code for a precise visualization with the identified trends.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To analyze and visualize the sales data by store for November 2021, I'll first look up the relevant data and then generate a visualization code. Here's our approach:\n",
       "\n",
       "1. The `lookup_sales_data` function will provide the actual sales data for the November 2021 period across different stores.\n",
       "2. After retrieving the data, the `analyze_sales_data` function will assist in extracting trends and insights from the dataset.\n",
       "3. Finally, the `generate_visualization` function will create a Python code snippet based on the analyzed data to produce a visualization (like a bar chart or line graph).\n",
       "\n",
       "Let's proceed with these steps:\n",
       "\n",
       "- I will use the `lookup_sales_data` function to fetch the required data.\n",
       "- Once I have that, `analyze_sales_data` will help in identifying patterns in sales by store.\n",
       "- Finally, `generate_visualization` will create Python code for a visualization of this sales data.\n",
       "\n",
       "Please, provide access to execute these functions, so we can generate the visualization code and identify trends. Because I am a text-based AI, I can't directly execute Python code or access external databases to get the data in real-time. However, I can lead you on the correct path to achieve this from within our simulation environment.\n",
       "\n",
       "Suppose, after fetching and analyzing data, insights are as follows:\n",
       "\n",
       "- Trends in sales vary widely across different stores.\n",
       "- Some stores exhibit a significant uplift in sales, possibly due to specific promotions.\n",
       "- Others show a slight increase, possibly depending on seasonality or customer base size.\n",
       "- In some regional segments, there is a consistent increase in sales compared to the previous month and the same period last year.\n",
       "\n",
       "With this analytical foundation, we could then develop a Python code snippet for visualization such as:\n",
       "\n",
       "```python\n",
       "import matplotlib.pyplot as plt\n",
       "import pandas as pd\n",
       "\n",
       "# Suppose df_sales is the DataFrame containing the sales data\n",
       "# from the latest lookup_sales_data call, including 'Store', 'Sale_Date', and 'Sales'\n",
       "\n",
       "# Filtering for November 2021\n",
       "nov_ Sales_data = df_sales[(pd.to_datetime(df_sales['Sale_Date']).dt.month == 11)]\n",
       "\n",
       "# Create a bar chart\n",
       "nov_Sales_data.groupby('Store')['Sales'].sum().plot(kind='bar')\n",
       "plt.title('Sales by Store in November 2021')\n",
       "plt.xlabel('Store')\n",
       "plt.ylabel('Total Sales')\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "Please allow me to fetch the real data and run this code for a precise visualization with the identified trends."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result)\n",
    "# you can also print a formatted version of the result\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa963d4-77da-4f5b-b8bf-6cb305929e2b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> 📒 &nbsp; For more help, please see the <em>\"Appendix – Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
