{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b5ff6a-45fb-4cfa-a875-b5dbfe61b4b5",
   "metadata": {},
   "source": [
    "# Lesson 5: Human in the Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aac9f2-6cc8-4133-b8f4-40f3c81e7a67",
   "metadata": {},
   "source": [
    "**Lesson objective**: Get feedback on answers from a human operator\n",
    "\n",
    "In this lab, you’ll learn how to make Workflows easy to iterate on answers to the questionnaire by getting feedback on answers from the human operator and re-answering when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54f338",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the notebook cell by cell. Please try to avoid running all cells at once.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dffa58e-3474-4c4f-8590-2479dae67252",
   "metadata": {
    "height": 385
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")\n",
    "from IPython.display import display, HTML\n",
    "from helper import extract_html_content\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764d413d-14ae-4ec9-a46b-f86694dba9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "MODEL_NAME = \"ibm-granite/granite-3.3-2b-instruct\"\n",
    "\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "model = OpenAILike(\n",
    "  model=MODEL_NAME,\n",
    "  api_key=API_KEY,\n",
    "  api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "  context_window=1234,\n",
    "  is_chat_model=True,  # supports chat completions\n",
    "  is_function_calling_model=True # supports tools/functions in the api\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a19d34f-b70c-4a6a-934e-bf77a94c7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "embed_model = HuggingFaceEmbedding()\n",
    "\n",
    "Settings.llm = model\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "Settings.num_output = 512\n",
    "Settings.context_window = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de39fa29-12ac-4b3e-9d1e-94852b096839",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d56f7-de48-4e1f-a288-a4c51db27251",
   "metadata": {},
   "source": [
    "## Adding a feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251da79-e354-4dba-8d49-67fa7278a11d",
   "metadata": {},
   "source": [
    "Here's what you built in lesson 4:\n",
    "\n",
    "<img width=\"400\" src=\"images/L4.png\">\n",
    "\n",
    "LLMs are amazing, but they are best used to augment rather than replace a human. Your current form-filler does an excellent job figuring out what fields need to be filled in, and gets most of the fields right, but there are a couple where it needs a little help. To take care of those, you'll create a \"human in the loop\" workflow, where you can optionally provide feedback to the agent you've created and have it incorporated into the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b6dd6-9476-4b72-a7a5-9aa3ac2f2d5b",
   "metadata": {},
   "source": [
    "This is what you'll implement in this notebook:\n",
    "\n",
    "<img width=\"500\" src=\"images/L5.png\">\n",
    "\n",
    "The changes you're going to make here are:\n",
    "1. Use the `InputRequiredEvent` and `HumanResponseEvent`, new special events specifically designed to allow you to exit the workflow, and get feedback back into it.\n",
    "2. You used to have a single step which parsed your form and fired off all your questions. Since we now might loop back and ask questions several times, we don't need to parse the form every time, so we'll split up those steps. This kind of refactoring is very common as you create a more complex workflow:\n",
    "   - Your new `generate_questions` step will be triggered either by a `GenerateQuestionsEvent`, triggered by the form parser, or by a `FeedbackEvent`, which is the loop we'll take after getting feedback.\n",
    "3. `fill_in_application` will emit an `InputRequiredEvent`, and in the `external_step` you'll wait for a `HumanResponseEvent`. This will pause the whole workflow waiting for outside input.\n",
    "4. Finally, you'll use the LLM to parse the feedback and decide whether it means you should continue and output the results, or if you need to loop back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6a7149-ded2-48b0-be39-eb32a9a22cca",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "# new!\n",
    "from llama_index.core.workflow import InputRequiredEvent, HumanResponseEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c7ef5a-0a39-41a9-adc1-8785c7f644ee",
   "metadata": {
    "height": 284
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str\n",
    "    \n",
    "class ResponseEvent(Event):\n",
    "    response: str\n",
    "\n",
    "# new!\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str\n",
    "\n",
    "class GenerateQuestionsEvent(Event):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd98cd7-1b98-4d26-976e-d2f9d1cea668",
   "metadata": {
    "height": 2527
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: model\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = model\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=\n",
    "                                                           self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = SimpleDirectoryReader(ev.resume_file).load_data()\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=embed_model\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # new - separated the form parsing from the question generation\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        reader = SimpleDirectoryReader(\n",
    "            input_files=[ev.application_form]\n",
    "        )\n",
    "        \n",
    "        result = reader.load_data()\n",
    "\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result}</form>. Return JSON ONLY, no markdown.\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # new - this step can get triggered either by GenerateQuestionsEvent or a FeedbackEvent\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "        \n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "  \n",
    "    # new - we now emit an InputRequiredEvent\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # new! save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # new! Let's get a human in the loop\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # new! Accept the feedback.\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "        # verdict = result.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1112a0-32c6-4db7-933e-c03ff649cd8b",
   "metadata": {},
   "source": [
    "Okay! Your workflow is now ready to get some feedback, but how do we actually get it? The `InputRequiredEvent` is an event in the event stream, just like the `ProgressEvents` and `TextEvents` you've seen in lesson 2. You can intercept it the same way you did those, and use the `send_event` method on the context to send back a `HumanResponseEvent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5cce3c-dde1-43ac-b52d-a0a4c3239210",
   "metadata": {
    "height": 385
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8046/4163393584.py:56: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"fields_to_fill\", fields)\n",
      "/tmp/ipykernel_8046/4163393584.py:65: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  fields = await ctx.get(\"fields_to_fill\")\n",
      "/tmp/ipykernel_8046/4163393584.py:76: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"total_fields\", len(fields))\n",
      "/tmp/ipykernel_8046/4163393584.py:89: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  total_fields = await ctx.get(\"total_fields\")\n",
      "/tmp/ipykernel_8046/4163393584.py:109: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"filled_form\", str(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Field: First Name\n",
      "Response: Sarah\n",
      "\n",
      "Field: Last Name\n",
      "Response: Chen\n",
      "\n",
      "Field: Email\n",
      "Response: sarah.chen@email.com\n",
      "\n",
      "Field: Phone\n",
      "Response: Not provided in the context.\n",
      "\n",
      "Field: Linkedin\n",
      "Response: linkedin.com/in/sarahcodes\n",
      "\n",
      "Field: Project Portfolio\n",
      "1. EcoTrack: A full-stack application built with React, Node.js, and MongoDB, designed to track carbon footprints with personalized sustainability recommendations. Featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\"\n",
      "2. ChatFlow: A real-time chat application using WebSocket protocol and React, featuring end-to-end encryption and message persistence, serving 5000+ monthly active users.\n",
      "\n",
      "Field: Degree\n",
      "Response: Bachelor of Science in Computer Science from the University of California, Berkeley, graduated in 2017.\n",
      "\n",
      "Field: Graduation Date\n",
      "Response: 2017\n",
      "\n",
      "Field: Current Job title\n",
      "Response: Junior Web Developer\n",
      "\n",
      "Field: Current Employer\n",
      "Response: TechFlow Solutions, San Francisco, CA\n",
      "\n",
      "Field: Technical Skills\n",
      "1. Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library\n",
      "2. Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB\n",
      "3. Additional: Webpack, Babel\n",
      "\n",
      "Field: Describe why you’re a good fit for this position\n",
      "Sarah Chen is a seasoned Full Stack Web Developer with over 6 years of experience in crafting scalable web applications and microservices. She specializes in React, Node.js, and cloud architecture, with a proven track record of leading technical teams and implementing CI/CD pipelines that reduced deployment time by 40%. Her expertise includes architecting and implementing microservices-based e-commerce platforms and rebuilding flagship products using React and Node.js. Her technical skills span a wide range of frontend and backend technologies, including React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB. She also has experience with GraphQL API gateway and end-to-end encryption for real-time chat applications. Her commitment to clean code, accessibility, and mentoring junior developers makes her a valuable asset for the Senior Web Developer position.\n",
      "\n",
      "Field: Do you have 5 years of experience in React?\n",
      "Response: While the resume doesn't explicitly state 5 years of experience in React, Sarah Chen has over 6 years of experience in web development, with a strong focus on React. She has been a Full Stack Web Developer since January 2022, leading a team in implementing a React-based e-commerce platform. Prior to that, she worked as a Senior Full Stack Developer at TechFlow Solutions from March 2019 to December 2021, extensively utilizing React and Node.js. Her proficiency and extensive use of React across various projects suggest more than 5 years of experience.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How does this look? Give me any feedback you have on any of the answers. great\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM says the verdict was OKAY\n",
      "Agent complete! Here's your final result:\n",
      "Field: First Name\n",
      "Response: Sarah\n",
      "\n",
      "Field: Last Name\n",
      "Response: Chen\n",
      "\n",
      "Field: Email\n",
      "Response: sarah.chen@email.com\n",
      "\n",
      "Field: Phone\n",
      "Response: Not provided in the context.\n",
      "\n",
      "Field: Linkedin\n",
      "Response: linkedin.com/in/sarahcodes\n",
      "\n",
      "Field: Project Portfolio\n",
      "1. EcoTrack: A full-stack application built with React, Node.js, and MongoDB, designed to track carbon footprints with personalized sustainability recommendations. Featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\"\n",
      "2. ChatFlow: A real-time chat application using WebSocket protocol and React, featuring end-to-end encryption and message persistence, serving 5000+ monthly active users.\n",
      "\n",
      "Field: Degree\n",
      "Response: Bachelor of Science in Computer Science from the University of California, Berkeley, graduated in 2017.\n",
      "\n",
      "Field: Graduation Date\n",
      "Response: 2017\n",
      "\n",
      "Field: Current Job title\n",
      "Response: Junior Web Developer\n",
      "\n",
      "Field: Current Employer\n",
      "Response: TechFlow Solutions, San Francisco, CA\n",
      "\n",
      "Field: Technical Skills\n",
      "1. Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library\n",
      "2. Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB\n",
      "3. Additional: Webpack, Babel\n",
      "\n",
      "Field: Describe why you’re a good fit for this position\n",
      "Sarah Chen is a seasoned Full Stack Web Developer with over 6 years of experience in crafting scalable web applications and microservices. She specializes in React, Node.js, and cloud architecture, with a proven track record of leading technical teams and implementing CI/CD pipelines that reduced deployment time by 40%. Her expertise includes architecting and implementing microservices-based e-commerce platforms and rebuilding flagship products using React and Node.js. Her technical skills span a wide range of frontend and backend technologies, including React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, and MongoDB. She also has experience with GraphQL API gateway and end-to-end encryption for real-time chat applications. Her commitment to clean code, accessibility, and mentoring junior developers makes her a valuable asset for the Senior Web Developer position.\n",
      "\n",
      "Field: Do you have 5 years of experience in React?\n",
      "Response: While the resume doesn't explicitly state 5 years of experience in React, Sarah Chen has over 6 years of experience in web development, with a strong focus on React. She has been a Full Stack Web Developer since January 2022, leading a team in implementing a React-based e-commerce platform. Prior to that, she worked as a Senior Full Stack Developer at TechFlow Solutions from March 2019 to December 2021, extensively utilizing React and Node.js. Her proficiency and extensive use of React across various projects suggest more than 5 years of experience.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8046/4163393584.py:136: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  return StopEvent(result=await ctx.get(\"filled_form\"))\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "handler = w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        print(\"We've filled in your form! Here are the results:\\n\")\n",
    "        print(event.result)\n",
    "        # now ask for input from the keyboard\n",
    "        response = input(event.prefix)\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=response\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da01c5-050a-4319-b9dc-39e55cc4bd7e",
   "metadata": {},
   "source": [
    "## Using the Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6cf5f-148e-472e-9526-dac9a21364c8",
   "metadata": {},
   "source": [
    "Okay! Now let's further modify things to actually do something useful with the feedback in `generate_questions` step. This involves checking if there's feedback, and appending it to the questions. In this simple example, we're going to append the feedback to every question in case it's relevant, but a more sophisticated agent might apply it only to the fields where the feedback applied.\n",
    "\n",
    "<img width=\"500\" src=\"images/L5-use_feedback.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081d90a7-95a6-4b02-914b-6aa09accb0c5",
   "metadata": {
    "height": 2646
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: model\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = model\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=\n",
    "                                                           self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = SimpleDirectoryReader(ev.resume_file).load_data()\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=embed_model\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # form parsing\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        reader = SimpleDirectoryReader(\n",
    "            input_files=[ev.application_form]\n",
    "        )\n",
    "        \n",
    "        result = reader.load_data()\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result}</form>. Return JSON ONLY, no markdown.\")\n",
    "        # fields = json.loads(raw_json)[\"fields\"]\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # generate questions\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "\n",
    "            # new! Is there feedback? If so, add it to the query:\n",
    "            if hasattr(ev,\"feedback\"):\n",
    "                question += f\"\"\"\n",
    "                    \\nWe previously got feedback about how we answered the questions.\n",
    "                    It might not be relevant to this particular field, but here it is:\n",
    "                    <feedback>{ev.feedback}</feedback>\n",
    "                \"\"\"\n",
    "            \n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "        \n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "  \n",
    "    # Get feedback from the human\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # Fire off the feedback request\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # Accept the feedback when a HumanResponseEvent fires\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230bc38-40cb-43d2-80ad-b179b96c2b82",
   "metadata": {},
   "source": [
    "Now run the workflow and give feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27001072-04b8-4459-b61b-f7cc0a441b37",
   "metadata": {
    "height": 385
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8046/1319504359.py:54: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"fields_to_fill\", fields)\n",
      "/tmp/ipykernel_8046/1319504359.py:63: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  fields = await ctx.get(\"fields_to_fill\")\n",
      "/tmp/ipykernel_8046/1319504359.py:83: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"total_fields\", len(fields))\n",
      "/tmp/ipykernel_8046/1319504359.py:96: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  total_fields = await ctx.get(\"total_fields\")\n",
      "/tmp/ipykernel_8046/1319504359.py:116: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"filled_form\", str(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Field: First Name\n",
      "Response: Sarah\n",
      "\n",
      "Field: Last Name\n",
      "Response: Chen\n",
      "\n",
      "Field: Email\n",
      "Response: sarah.chen@email.com\n",
      "\n",
      "Field: Linkedin\n",
      "Response: linkedin.com/in/sarahcodes\n",
      "\n",
      "Field: Project Portfolio\n",
      "Response: The candidate, Sarah Chen, has developed applications such as EcoTrack (React, Node.js, MongoDB) and ChatFlow (WebSocket, React). EcoTrack was featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\". She has experience in microservices architecture, having architected and implemented a platform serving 100K+ daily users at TechFlow Solutions.\n",
      "\n",
      "Field: Degree\n",
      "Response: Bachelor of Science in Computer Science from the University of California, Berkeley, graduated in 2017.\n",
      "\n",
      "Field: Graduation Date\n",
      "Response: Around the end of 2017, assuming a four-year program.\n",
      "\n",
      "Field: Current Job title\n",
      "Response: Senior Full Stack Developer\n",
      "\n",
      "Field: Current Employer\n",
      "Response: TechFlow Solutions, San Francisco, CA\n",
      "\n",
      "Field: Technical Skills\n",
      "Response: Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library. Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB. Additional: TypeScript, Webpack, Babel.\n",
      "\n",
      "Field: Describe why you’re a good fit for this position\n",
      "Response: Sarah Chen is a seasoned Full Stack Web Developer with over 6 years of experience, specializing in React and microservices. She has led technical teams, implemented CI/CD pipelines, and architected e-commerce platforms. Her expertise includes reducing deployment time by 40% and improving code quality. She has worked with React, Node.js, Express.js, GraphQL, REST APIs, PostgreSQL, and MongoDB, and has contributed to projects like EcoTrack and ChatFlow.\n",
      "\n",
      "Field: Do you have 5 years of experience in React?\n",
      "Response: While not explicitly stated, Sarah Chen's extensive experience with React across various projects suggests she has substantial proficiency in this technology, indicating over 5 years of experience.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How does this look? Give me any feedback you have on any of the answers. okay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM says the verdict was FEEDBACK\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Field: First Name\n",
      "Response: Sarah\n",
      "\n",
      "Field: Last Name\n",
      "Response: Chen\n",
      "\n",
      "Field: Email\n",
      "Response: LinkedIn profile is linkedin.com/in/sarahchen.\n",
      "\n",
      "Field: Phone\n",
      "Response: No direct information available.\n",
      "\n",
      "Field: Linkedin\n",
      "Response: linkedin.com/in/sarahchen\n",
      "\n",
      "Field: Project Portfolio\n",
      "Response: The candidate has developed applications such as EcoTrack (React, Node.js, MongoDB) and ChatFlow (WebSocket protocol, React), showcasing skills in full-stack web development. EcoTrack featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\"\n",
      "\n",
      "Field: Degree\n",
      "Response: Bachelor of Science in Computer Science from the University of California, Berkeley, with a minor in User Experience Design. Graduated in 2017.\n",
      "\n",
      "Field: Graduation Date\n",
      "Response: Likely graduated in 2017.\n",
      "\n",
      "Field: Current Job title\n",
      "Response: Senior Full Stack Developer\n",
      "\n",
      "Field: Current Employer\n",
      "Response: TechFlow Solutions, San Francisco, CA\n",
      "\n",
      "Field: Technical Skills\n",
      "Response: Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library. Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB. Additional: TypeScript, Webpack, Babel.\n",
      "\n",
      "Field: Describe why you’re a good fit for this position\n",
      "Response: With over 6 years of experience as a Full Stack Web Developer, Sarah Chen has a proven track record of leading technical teams, implementing CI/CD pipelines, and architecting complex systems. Her expertise in React, Node.js, and cloud architecture, along with her ability to mentor junior developers, makes her a strong candidate for the Senior Web Developer position.\n",
      "\n",
      "Field: Do you have 5 years of experience in React?\n",
      "Response: Yes, Sarah Chen has substantial experience in React, having worked extensively with it for over 6 years, including leading a team in rebuilding a product using React and Node.js at TechFlow Solutions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How does this look? Give me any feedback you have on any of the answers. good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM says the verdict was OKAY\n",
      "Agent complete! Here's your final result:\n",
      "Field: First Name\n",
      "Response: Sarah\n",
      "\n",
      "Field: Last Name\n",
      "Response: Chen\n",
      "\n",
      "Field: Email\n",
      "Response: LinkedIn profile is linkedin.com/in/sarahchen.\n",
      "\n",
      "Field: Phone\n",
      "Response: No direct information available.\n",
      "\n",
      "Field: Linkedin\n",
      "Response: linkedin.com/in/sarahchen\n",
      "\n",
      "Field: Project Portfolio\n",
      "Response: The candidate has developed applications such as EcoTrack (React, Node.js, MongoDB) and ChatFlow (WebSocket protocol, React), showcasing skills in full-stack web development. EcoTrack featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\"\n",
      "\n",
      "Field: Degree\n",
      "Response: Bachelor of Science in Computer Science from the University of California, Berkeley, with a minor in User Experience Design. Graduated in 2017.\n",
      "\n",
      "Field: Graduation Date\n",
      "Response: Likely graduated in 2017.\n",
      "\n",
      "Field: Current Job title\n",
      "Response: Senior Full Stack Developer\n",
      "\n",
      "Field: Current Employer\n",
      "Response: TechFlow Solutions, San Francisco, CA\n",
      "\n",
      "Field: Technical Skills\n",
      "Response: Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library. Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB. Additional: TypeScript, Webpack, Babel.\n",
      "\n",
      "Field: Describe why you’re a good fit for this position\n",
      "Response: With over 6 years of experience as a Full Stack Web Developer, Sarah Chen has a proven track record of leading technical teams, implementing CI/CD pipelines, and architecting complex systems. Her expertise in React, Node.js, and cloud architecture, along with her ability to mentor junior developers, makes her a strong candidate for the Senior Web Developer position.\n",
      "\n",
      "Field: Do you have 5 years of experience in React?\n",
      "Response: Yes, Sarah Chen has substantial experience in React, having worked extensively with it for over 6 years, including leading a team in rebuilding a product using React and Node.js at TechFlow Solutions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8046/1319504359.py:142: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  return StopEvent(result=await ctx.get(\"filled_form\"))\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "handler = w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        print(\"We've filled in your form! Here are the results:\\n\")\n",
    "        print(event.result)\n",
    "        # now ask for input from the keyboard\n",
    "        response = input(event.prefix)\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=response\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46b976",
   "metadata": {},
   "source": [
    "## Workflow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfe9e8-9aed-4977-a5fc-07976b5e17a8",
   "metadata": {},
   "source": [
    "You can visualize the workflow you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9526d28-a1e9-43fe-baed-706a3c3adbc2",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflows/feedback_workflow.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"InputRequiredEvent\", \"label\": \"InputRequiredEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#BEDAE4\", \"id\": \"external_step\", \"label\": \"external_step\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"generate_questions\", \"label\": \"generate_questions\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"GenerateQuestionsEvent\", \"label\": \"GenerateQuestionsEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"FeedbackEvent\", \"label\": \"FeedbackEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"get_feedback\", \"label\": \"get_feedback\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"HumanResponseEvent\", \"label\": \"HumanResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\", \"title\": null}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"InputRequiredEvent\"}, {\"arrows\": \"to\", \"from\": \"InputRequiredEvent\", \"to\": \"external_step\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"generate_questions\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"GenerateQuestionsEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"FeedbackEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"FeedbackEvent\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"HumanResponseEvent\", \"to\": \"get_feedback\"}, {\"arrows\": \"to\", \"from\": \"external_step\", \"to\": \"HumanResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"GenerateQuestionsEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/feedback_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efde360-1bbd-48b7-8c70-0aa7745b24ec",
   "metadata": {},
   "source": [
    "## Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843af32-46d9-410d-a21d-8c132a8a2421",
   "metadata": {},
   "source": [
    "The agent now responds to Human-in-the-loop feedback and produces more accurate filled forms as a result. Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
