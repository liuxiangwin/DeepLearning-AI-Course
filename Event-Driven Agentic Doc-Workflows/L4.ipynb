{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Lesson 4: Form Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdf36b-0ddd-4b79-9ea7-b1be3860011b",
   "metadata": {},
   "source": [
    "**Lesson objective**: Incorporate form parsing to the workflow\n",
    "\n",
    "In your previous lesson, you used LlamaParse to parse a resume, and included parsing instructions. You'll do that again this time, but the instructions are going to be more advanced -- you're going to get it to read an application form and convert it into a list of fields that need to be filled in, and return that as a JSON object. You will then incorporate these steps in the workflow you started building in the previous lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ddcea",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the notebook cell by cell. Please try to avoid running all cells at once.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a3b851-ffd0-49f8-a482-4b19a7e1b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "MODEL_NAME = \"ibm-granite/granite-3.3-2b-instruct\"\n",
    "\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "model = OpenAILike(\n",
    "  model=MODEL_NAME,\n",
    "  api_key=API_KEY,\n",
    "  api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "  context_window=1234,\n",
    "  is_chat_model=True,  # supports chat completions\n",
    "  is_function_calling_model=True # supports tools/functions in the api\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {
    "height": 402
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "# from llama_parse import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")\n",
    "from helper import get_openai_api_key, get_llama_cloud_api_key\n",
    "from IPython.display import display, HTML\n",
    "from helper import extract_html_content\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142d4e-48b4-43ec-ac7c-b608a8ba23c7",
   "metadata": {},
   "source": [
    "## Parsing an Application Form with LlamaParse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ada06-8cc7-4c4e-b4fb-268a0515addd",
   "metadata": {},
   "source": [
    "Let's create a parser with our new parsing instructions, including formatting instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0039610-c02e-4e7e-9c9f-1dc56450543d",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "# parser = LlamaParse(\n",
    "#     api_key=llama_cloud_api_key,\n",
    "#     base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "#     result_type=\"markdown\",\n",
    "#     content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "#     formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "# )\n",
    "\n",
    "\n",
    "# load pdf\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "# loader_A = PyPDFLoader(\"./data/fake_application_form.pdf\")\n",
    "# documents = loader_A.load()\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "# documents = SimpleDirectoryReader(\"./data/fake_application_form.pdf\").load_data()\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/fake_application_form.pdf\"]\n",
    ")\n",
    "\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "# result = parser.load_data(\"data/fake_application_form.pdf\")[0]\n",
    "\n",
    "result = documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e97a9-2669-4cb9-b0ac-e42bfb14d332",
   "metadata": {},
   "source": [
    "As print out the results, you can see it has pulled all the boxes in the form and correctly turned them into field names to be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53149fea-7383-4c39-a58c-5836857f69b7",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "# print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95399d6d-1abd-4b3d-a7b1-7c9ba34e0c12",
   "metadata": {},
   "source": [
    "A useful thing LLMs can do is turn human-readable formats into machine-readable ones. You will ask the LLM to turn the list into a JSON object with a list of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d24516-ef60-4be2-81a8-6c016dc9665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "embed_model = HuggingFaceEmbedding()\n",
    "\n",
    "Settings.llm = model\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "Settings.num_output = 512\n",
    "Settings.context_window = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "# llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "raw_json = llm.complete(\n",
    "    f\"\"\"\n",
    "    This is a parsed form.\n",
    "    Convert it into a JSON object containing only the list \n",
    "    of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "    <form>{result.text}</form>. \n",
    "    Return JSON ONLY, no markdown.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe444b5-b18a-4b5b-9a9f-dd0942fff0b9",
   "metadata": {},
   "source": [
    "Here's the raw JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"fields\": [\\n    \"First Name\",\\n    \"Last Name\",\\n    \"Email\",\\n    \"Phone\",\\n    \"Linkedin\",\\n    \"Project Portfolio\",\\n    \"Degree\",\\n    \"Graduation Date\",\\n    \"Current Job Title\",\\n    \"Current Employer\",\\n    \"Technical Skills\",\\n    \"Describe why you’re a good fit for this position\",\\n    \"Do you have 5 years of experience in React?\"\\n  ]\\n}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_json.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbf060-bed0-40a1-9173-f85eaa7e4978",
   "metadata": {},
   "source": [
    "And you can print out the fields one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {
    "height": 80
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Name\n",
      "Last Name\n",
      "Email\n",
      "Phone\n",
      "Linkedin\n",
      "Project Portfolio\n",
      "Degree\n",
      "Graduation Date\n",
      "Current Job Title\n",
      "Current Employer\n",
      "Technical Skills\n",
      "Describe why you’re a good fit for this position\n",
      "Do you have 5 years of experience in React?\n"
     ]
    }
   ],
   "source": [
    "fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "for field in fields:\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabc0b2-1258-45c9-954a-67de4baca6c9",
   "metadata": {},
   "source": [
    "Now that you know how to parse the job application form, you will add this processing to the workflow of lesson 3. You will do that in two steps as shown in this figure:\n",
    "\n",
    "<img width=\"700\" src=\"images/L4-diagrams.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc1088-2bd3-4ce8-a491-e8acd9cbde6b",
   "metadata": {},
   "source": [
    "## Adding a Form Parser to the Workflow (first update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbb61b-8e74-45d0-ae26-d8ecc40b42c7",
   "metadata": {},
   "source": [
    "Now let's take the workflow you built in the last lesson and add your parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79094e64-7aa0-47d5-8974-8b3b2200d111",
   "metadata": {},
   "source": [
    "Your `set_up` step now emits a `ParseFormEvent` which triggers your new step, `parse_form`. For the moment you can leave the ask_questions step untouched, it will be updated in another section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {
    "height": 1337
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: model\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        # self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.llm = model\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            # documents = LlamaParse(\n",
    "            #     api_key=llama_cloud_api_key,\n",
    "            #     base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            #     result_type=\"markdown\",\n",
    "            #     content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            # ).load_data(ev.resume_file)\n",
    "            documents = SimpleDirectoryReader(ev.resume_file).load_data()\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=embed_model\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        # parser = LlamaParse(\n",
    "        #     api_key=llama_cloud_api_key,\n",
    "        #     base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "        #     result_type=\"markdown\",\n",
    "        #     content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "        #     formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        # )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        # result = parser.load_data(ev.application_form)[0]\n",
    "\n",
    "        # result = SimpleDirectoryReader(ev.application_form).load_data()\n",
    "\n",
    "        reader = SimpleDirectoryReader(\n",
    "            input_files=[ev.application_form]\n",
    "        )\n",
    "        \n",
    "        result = reader.load_data()\n",
    "        \n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        \n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        for field in fields:\n",
    "            print(field)\n",
    "        return StopEvent(result=\"Dummy event\")\n",
    "\n",
    "    # will be edited in the next section\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> StopEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return StopEvent(result=response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {
    "height": 97
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n",
      "id_\n",
      "embedding\n",
      "metadata\n",
      "relationships\n",
      "text_resource\n",
      "path\n",
      "url\n",
      "mimetype\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=60, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"./data/fake_resume.pdf\",\n",
    "    application_form=\"./data/fake_application_form.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656e32f-19ce-4f45-883e-5c89cb800d9e",
   "metadata": {},
   "source": [
    "## Generating Questions (second update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4a3ee-0d76-4402-9221-12dfd2755269",
   "metadata": {},
   "source": [
    "Excellent! Your workflow knows what fields it needs answers for. In this next iteration, you can fire off one `QueryEvent` for each of the fields, so they'll be executed concurrently (we talked about doing concurrent steps in Lesson 2). \n",
    "\n",
    "<img width=\"700\" src=\"images/L4-diag-2.png\">\n",
    "\n",
    "\n",
    "The changes you're going to make are:\n",
    "* Generate a `QueryEvent` for each of the questions you pulled out of the form\n",
    "* Create a `fill_in_application` step which will take all the responses to the questions and aggregate them into a coherent response\n",
    "* Add a `ResponseEvent` to pass the results of queries to `fill_in_application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "479183ef-c912-4fb9-8b5d-348e1942e713",
   "metadata": {
    "height": 182
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str\n",
    "\n",
    "# new!\n",
    "class ResponseEvent(Event):\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a16626b-75c7-4b2f-84c5-94688530cc89",
   "metadata": {
    "height": 1864
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: model\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        # self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.llm = model\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            documents = SimpleDirectoryReader(ev.resume_file).load_data()\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=embed_model\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        reader = SimpleDirectoryReader(\n",
    "            input_files=[ev.application_form]\n",
    "        )\n",
    "        \n",
    "        result = reader.load_data()\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        # new!\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=f\"How would you answer this question about the candidate? {field}\"\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # new!\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> StopEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "        return StopEvent(result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8daf0ba9-d3e7-4380-be07-368b6ec41f29",
   "metadata": {
    "height": 114
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5855/2296005844.py:88: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
      "  await ctx.set(\"total_fields\", len(fields))\n",
      "/tmp/ipykernel_5855/2296005844.py:100: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
      "  total_fields = await ctx.get(\"total_fields\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: First Name\n",
      "Response: Sarah\n",
      "\n",
      "Field: Last Name\n",
      "Response: Chen\n",
      "\n",
      "Field: Email\n",
      "Response: sarah.chen@email.com\n",
      "\n",
      "Field: Phone\n",
      "Response: No direct information available.\n",
      "\n",
      "Field: Linkedin\n",
      "Response: LinkedIn profile can be accessed at linkedin.com/in/sarahchen.\n",
      "\n",
      "Field: Project Portfolio\n",
      "Response: EcoTrack (full-stack application with React, Node.js, MongoDB, and machine learning for sustainability recommendations) and ChatFlow (real-time chat application using WebSocket protocol and React with end-to-end encryption and message persistence).\n",
      "\n",
      "Field: Degree\n",
      "Response: Bachelor of Science in Computer Science from the University of California, Berkeley, graduated in 2017.\n",
      "\n",
      "Field: Graduation Date\n",
      "Response: Graduated in 2017.\n",
      "\n",
      "Field: Current Job title\n",
      "Response: Senior Full Stack Developer\n",
      "\n",
      "Field: Current Employer\n",
      "Response: TechFlow Solutions, San Francisco, CA\n",
      "\n",
      "Field: Technical Skills\n",
      "Response: Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library. Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB. Additional: Webpack, Babel, Docker.\n",
      "\n",
      "Field: Describe why you’re a good fit for this position\n",
      "Response: With 6+ years of experience in crafting scalable web applications and microservices, Sarah Chen specializes in React, Node.js, and cloud architecture. Her professional experience includes leading technical teams, implementing CI/CD pipelines, and architecting microservices-based e-commerce platforms. She has a proven track record of improving code quality and reducing deployment times, aligning her skills with the Senior Web Developer position at Big Tech Co.\n",
      "\n",
      "Field: Do you have 5 years of experience in React?\n",
      "Response: While Sarah Chen has extensive experience with React, the resume does not explicitly state that she has exactly 5 years of experience in React. She has been proficient in React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, and Babel, using React in various projects, including leading a team in rebuilding a product using React and Node.js, and implementing a GraphQL API gateway.\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=120, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"./data/fake_resume.pdf\",\n",
    "    application_form=\"./data/fake_application_form.pdf\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff7243",
   "metadata": {},
   "source": [
    "## Workflow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a1393-35b9-4fe9-a741-2dbfbeba73c9",
   "metadata": {},
   "source": [
    "You can visualize the workflow you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6416a1f-c2c9-478b-b290-8cd89998da35",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflows/form_parsing_workflow.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\", \"title\": null}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/form_parsing_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38d509-755f-48f0-b340-1fa99314b531",
   "metadata": {},
   "source": [
    "## Cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e1158-b7ef-4b65-8a36-1fe628813d95",
   "metadata": {},
   "source": [
    "Your workflow takes all the fields in the form and generates plausible answers for all of them. There are a couple of fields where I think it can do better, and in the next lesson you'll add the ability to give that feedback to the agent and get it to try again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
