{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958c961c-02fd-47de-ad89-ec4d757bcffb",
   "metadata": {},
   "source": [
    "# L2: DSPy Programming - Signatures and Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78a748-1059-4643-a44a-f3a8eae034b7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce0bf6d-265f-4db3-ac55-bda52f21aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pymilvus 2.3.6 requires grpcio<=1.60.0,>=1.49.1, but you have grpcio 1.73.0 which is incompatible.\n",
      "grpcio-tools 1.73.0 requires protobuf<7.0.0,>=6.30.0, but you have protobuf 5.29.5 which is incompatible.\n",
      "grpcio-health-checking 1.73.0 requires protobuf<7.0.0,>=6.30.0, but you have protobuf 5.29.5 which is incompatible.\n",
      "kfp 2.9.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\n",
      "kfp 2.9.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "kfp-kubernetes 1.4.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\n",
      "kfp-pipeline-spec 0.4.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv==1.0.0 dspy==2.6.23 mlflow==2.21.3 openai==1.61.0 pydantic==2.11.3 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e035d9-152b-4f5b-9b89-487e556618de",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72705217-455a-485d-a12f-4b4f60c0fd6b",
   "metadata": {},
   "source": [
    "### Set up API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ebd71-0dbd-42b8-84fd-975610e4d253",
   "metadata": {},
   "source": [
    "### Configure the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdfb288-5f7d-437d-9fea-5487dd0d9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\n",
    "  token=\"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\", # ADD YOUR TOKEN HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96024cd-1c57-45b1-9424-eccbc4d87b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ['ATHINA_API_KEY'] = \"IhrJrr0krTMRA9ogqi5aaD4ZuYuvMcdG\"\n",
    "\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL_NAME=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "MODEL_NAME=\"ibm-granite/granite-3.3-2b-instruct\"\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    api_key=API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48bd6ed-0d8f-4348-a09c-ab860b63e40c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "# dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))\n",
    "# model=\"huggingface/meta-llama/Llama-3.2-1B\"\n",
    "lm_local = dspy.LM(\n",
    "    \"ibm-granite/granite-3.3-2b-instruct\",\n",
    "    custom_llm_provider=\"openai\",\n",
    "    api_base=f\"{INFERENCE_SERVER_URL}/v1\",  # local endpoint\n",
    "    api_key=API_KEY,  # empty api_key for local endpoint\n",
    "    model_type='chat',  # specify chat model type\n",
    "    cache=False  # disable caching\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm = lm_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e0fcc-4539-46e0-af97-a4c765acab8f",
   "metadata": {},
   "source": [
    "## Use DSPy built-in Module to Build a Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346f5302-0903-4595-97f7-818c637f11aa",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(dspy.Signature):\n",
    "    \"\"\"Classify the sentiment of a text.\"\"\"\n",
    "\n",
    "    text: str = dspy.InputField(desc=\"input text to classify sentiment\")\n",
    "    sentiment: int = dspy.OutputField(\n",
    "        desc=\"sentiment, the higher the more positive\", ge=0, le=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558d3e54-cbb8-4229-8d1c-7f9b37283048",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "str_signature = dspy.make_signature(\"text -> sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c1e4f-b241-4c26-ac91-c2fc2b54c6c6",
   "metadata": {},
   "source": [
    "### Create a Module to Interact with the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbcc28ff-181f-4a92-b7e8-370d39128904",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "predict = dspy.Predict(SentimentClassifier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ac1acd-6bc3-43be-829f-df4bbe30ddb3",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sentiment=7\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output = predict(text=\"I am feeling pretty happy!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a7eda0-ad5f-4cd5-a9e4-9e13934ed9d2",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is: 7\n",
      "The sentiment is: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"The sentiment is: {output.sentiment}\")\n",
    "print(f\"The sentiment is: {output['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5d025e-4c94-48af-b99c-62815ee1b84c",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sentiment=7\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# dspy.configure(lm=dspy.LM(\"openai/gpt-4o\"))\n",
    "dspy.settings.configure(lm = lm_local)\n",
    "print(predict(text=\"I am feeling pretty happy!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f2ee29-15b4-4a89-b09c-ec2b6b99b16b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))\n",
    "# dspy.settings.configure(lm = lm_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b9084-2b06-4c22-9683-0a2e4c0a45b0",
   "metadata": {},
   "source": [
    "### Wait, Where is My Prompt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a70885d-6cb0-4d90-bbf0-f5da296d5420",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-12T10:00:03.903111]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "Your output fields are:\n",
      "1. `sentiment` (int): sentiment, the higher the more positive\n",
      "Constraints: greater than or equal to: 0, less than or equal to: 10\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "{sentiment}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## sentiment ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## sentiment ## ]]\n",
      "7\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36f97e-5414-4749-939f-0bd1f20e3ab0",
   "metadata": {},
   "source": [
    "### Try a Different Built-in Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e86d738-468c-4269-bb51-8ecfc2b6ccfc",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The text expresses a positive emotion, specifically happiness. This is indicated by the use of the word \"pretty\" which intensifies the positive sentiment.',\n",
      "    sentiment=9\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(SentimentClassifier)\n",
    "\n",
    "output = cot(text=\"I am feeling pretty happy!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad92d6d2-554a-4d8a-b647-2f7c4ba97b08",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-12T10:00:11.545292]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `sentiment` (int): sentiment, the higher the more positive\n",
      "Constraints: greater than or equal to: 0, less than or equal to: 10\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "{sentiment}        # note: the value you produce must be a single int value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sentiment ## ]]` (must be formatted as a valid Python int), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The text expresses a positive emotion, specifically happiness. This is indicated by the use of the word \"pretty\" which intensifies the positive sentiment.\n",
      "\n",
      "[[ ## sentiment ## ]]\n",
      "9\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f2d32-2336-4a54-9c2c-ef41109125c1",
   "metadata": {},
   "source": [
    "### Use a Different Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa8ca69-13e8-47cc-9965-b0e280a383ce",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dspy.configure(adapter=dspy.JSONAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "984fa475-0220-4ab8-995f-492afa09385a",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning=\"The text expresses a positive emotion, specifically 'happy', which indicates a high sentiment score.\",\n",
      "    sentiment=9\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-12T10:00:12.940558]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `sentiment` (int): sentiment, the higher the more positive\n",
      "Constraints: greater than or equal to: 0, less than or equal to: 10\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"sentiment\": \"{sentiment}        # note: the value you produce must be a single int value\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `sentiment` (must be formatted as a valid Python int).\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\n",
      "  \"reasoning\": \"The text expresses a positive emotion, specifically 'happy', which indicates a high sentiment score.\",\n",
      "  \"sentiment\": 9\n",
      "}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cot(text=\"I am feeling pretty happy!\"))\n",
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22921dc6-d6ff-4306-82b7-60cc2ef09bff",
   "metadata": {},
   "source": [
    "## Build a Program with Custom Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757973e3-0716-4e6b-99ed-010ffb3e8390",
   "metadata": {
    "height": 1186
   },
   "outputs": [],
   "source": [
    "class QuestionGenerator(dspy.Signature):\n",
    "    \"\"\"Generate a yes or no question in order to guess the celebrity name in users' mind. You can ask in general or directly guess the name if you think the signal is enough. You should never ask the same question in the past_questions.\"\"\"\n",
    "    past_questions: list[str] = dspy.InputField(desc=\"past questions asked\")\n",
    "    past_answers: list[bool] = dspy.InputField(desc=\"past answers\")\n",
    "    new_question: str = dspy.OutputField(desc=\"new question that can help narrow down the celebrity name\")\n",
    "    guess_made: bool = dspy.OutputField(desc=\"If the new_question is the celebrity name guess, set to True, if it is still a general question set to False\")\n",
    "\n",
    "\n",
    "class Reflection(dspy.Signature):\n",
    "    \"\"\"Provide reflection on the guessing process\"\"\"\n",
    "    correct_celebrity_name: str = dspy.InputField(desc=\"the celebrity name in user's mind\")\n",
    "    final_guessor_question: str = dspy.InputField(desc=\"the final guess or question LM made\")\n",
    "    past_questions: list[str] = dspy.InputField(desc=\"past questions asked\")\n",
    "    past_answers: list[bool] = dspy.InputField(desc=\"past answers\")\n",
    "\n",
    "    reflection: str = dspy.OutputField(\n",
    "        desc=\"reflection on the guessing process, including what was done well and what can be improved\"\n",
    "    )\n",
    "\n",
    "def ask(prompt, valid_responses=(\"y\", \"n\")):\n",
    "    while True:\n",
    "        response = input(f\"{prompt} ({'/'.join(valid_responses)}): \").strip().lower()\n",
    "        if response in valid_responses:\n",
    "            return response\n",
    "        print(f\"Please enter one of: {', '.join(valid_responses)}\")\n",
    "\n",
    "class CelebrityGuess(dspy.Module):\n",
    "    def __init__(self, max_tries=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.question_generator = dspy.ChainOfThought(QuestionGenerator)\n",
    "        self.reflection = dspy.ChainOfThought(Reflection)\n",
    "\n",
    "        self.max_tries = 20\n",
    "\n",
    "    def forward(self):\n",
    "        celebrity_name = input(\"Please think of a celebrity name, once you are ready, type the name and press enter...\")\n",
    "        past_questions = []\n",
    "        past_answers = []\n",
    "\n",
    "        correct_guess = False\n",
    "\n",
    "        for i in range(self.max_tries):\n",
    "            question = self.question_generator(\n",
    "                past_questions=past_questions,\n",
    "                past_answers=past_answers,\n",
    "            )\n",
    "            answer = ask(f\"{question.new_question}\").lower() == \"y\"\n",
    "            past_questions.append(question.new_question)\n",
    "            past_answers.append(answer)\n",
    "\n",
    "            if question.guess_made and answer:\n",
    "                correct_guess = True\n",
    "                break\n",
    "\n",
    "        if correct_guess:\n",
    "            print(\"Yay! I got it right!\")\n",
    "        else:\n",
    "            print(\"Oops, I couldn't guess it right.\")\n",
    "\n",
    "        reflection = self.reflection(\n",
    "            correct_celebrity_name=celebrity_name,\n",
    "            final_guessor_question=question.new_question,\n",
    "            past_questions=past_questions,\n",
    "            past_answers=past_answers,\n",
    "        )\n",
    "        print(reflection.reflection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e7da57-2b07-404b-87ad-633dc751511b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "celebrity_guess = CelebrityGuess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cabb8dd3-cdcd-4d93-b04d-cd6915981cb5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please think of a celebrity name, once you are ready, type the name and press enter... steve curry\n",
      "Are you thinking of a female actor known for her role as Cristina in the popular medical drama 'Grey's Anatomy'? (y/n):  n\n",
      "Are you thinking of a celebrity who is known for their work in the entertainment industry, particularly in television dramas, and has won multiple Emmy Awards? (y/n):  n\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcelebrity_guess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/dspy/utils/callback.py:326\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m _get_active_callbacks(instance)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m call_id \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n\u001b[1;32m    330\u001b[0m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/dspy/primitives/program.py:32\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         output\u001b[38;5;241m.\u001b[39mset_lm_usage(usage_tracker\u001b[38;5;241m.\u001b[39mget_total_tokens())\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 48\u001b[0m, in \u001b[0;36mCelebrityGuess.forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tries):\n\u001b[1;32m     44\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestion_generator(\n\u001b[1;32m     45\u001b[0m         past_questions\u001b[38;5;241m=\u001b[39mpast_questions,\n\u001b[1;32m     46\u001b[0m         past_answers\u001b[38;5;241m=\u001b[39mpast_answers,\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_question\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     past_questions\u001b[38;5;241m.\u001b[39mappend(question\u001b[38;5;241m.\u001b[39mnew_question)\n\u001b[1;32m     50\u001b[0m     past_answers\u001b[38;5;241m.\u001b[39mappend(answer)\n",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m, in \u001b[0;36mask\u001b[0;34m(prompt, valid_responses)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mask\u001b[39m(prompt, valid_responses\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_responses\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m valid_responses:\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "celebrity_guess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c17054-4872-4ed7-a8a3-13162c0dad70",
   "metadata": {},
   "source": [
    "## Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae42d9-f703-4432-9910-82c4fbdae0e6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "celebrity_guess.save(\"dspy_program/celebrity.json\", save_program=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf744c20-9b74-4c1e-9fac-a56d54db47ff",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "celebrity_guess.load(\"dspy_program/celebrity.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bbeae-fc9a-48b8-ad73-f280e04dada6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "celebrity_guess.save(\"dspy_program/celebrity/\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb548d44-b176-4629-8fe3-57d0573181ac",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "loaded = dspy.load(\"dspy_program/celebrity/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d93f8c-e8d1-4408-9941-331cf68faae8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fdf73-27a5-4925-bfb7-343c6ac6c58e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226b779-6b8e-4ff9-a0a2-86df42c9499d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747385d3-6611-484f-b7c7-78564be67b0d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa5186-bc89-4b64-9639-5e51a53ec4e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92dddb-7808-4b51-9443-4ef903dfa39f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15b565-92b8-4637-bac9-5e53736873ba",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e3c41-ec8e-4624-a188-a90886158769",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302ec73-a9f4-4ab7-b548-b321688a35a8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce60cd9-d5a5-42f9-a375-b3ead2137e99",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347cbdb-b9ce-4029-90ad-c7cf38043df2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e3c7b-1fb4-478c-9ad4-bbf187a49b53",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e988337-bc5c-4f26-a6cb-a74cd694b746",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcce24-0aa3-44df-bbae-c49a9801522f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43556c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a8d0a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
